Metadata-Version: 2.4
Name: aura-ai
Version: 0.1.0
Summary: Aura AI â€“ terminal-first autonomous AI assistant
Author: Aura AI
Requires-Python: >=3.9
Description-Content-Type: text/markdown
Requires-Dist: pyyaml
Requires-Dist: requests
Requires-Dist: langchain-ollama
Requires-Dist: langchain-core
Requires-Dist: langchain-tavily
Requires-Dist: cryptography>=42.0.0
Requires-Dist: argon2-cffi>=23.1.0

# ğŸ¤– Aura â€” Local AI Assistant with Persistent Memory

Aura is a privacy-first, local AI assistant powered by Ollama.
It features **persistent identity**, **long-term memory**, **semantic (RAG) recall**, 
and **optional live web search** â€” all stored locally on your machine.

---

## âœ¨ Key Features

- ğŸ” **Persistent Identity**
  - One-time generated user ID
  - Memory survives restarts

- ğŸ§  **Hybrid Memory System**
  - Short-term chat memory
  - Long-term factual memory
  - Semantic vector memory (RAG)

- ğŸ” **Optional Web Search**
  - Uses Tavily (only when needed)
  - Disabled by default unless API key is set

- âš™ï¸ **Model Agnostic**
  - Uses Ollama
  - Switch models anytime

- ğŸ©º **Built-in Diagnostics**
  - Doctor command
  - Config migration
  - Model inspection

---

## ğŸ“¦ Installation

### 1. Prerequisites
- Python 3.10+
- Ollama installed and running

```bash
ollama pull deepseek-v3.1:671b-cloud


________________________________________________________________-------
git clone <your-repo>
cd aura
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
__________________________________________________________________-----
