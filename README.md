# ğŸ¤– Aura â€” Local AI Assistant with Persistent Memory

Aura is a privacy-first, local AI assistant powered by Ollama.
It features **persistent identity**, **long-term memory**, **semantic (RAG) recall**, 
and **optional live web search** â€” all stored locally on your machine.

---

## âœ¨ Key Features

- ğŸ” **Persistent Identity**
  - One-time generated user ID
  - Memory survives restarts

- ğŸ§  **Hybrid Memory System**
  - Short-term chat memory
  - Long-term factual memory
  - Semantic vector memory (RAG)

- ğŸ” **Optional Web Search**
  - Uses Tavily (only when needed)
  - Disabled by default unless API key is set

- âš™ï¸ **Model Agnostic**
  - Uses Ollama
  - Switch models anytime

- ğŸ©º **Built-in Diagnostics**
  - Doctor command
  - Config migration
  - Model inspection

---

## ğŸ“¦ Installation

### 1. Prerequisites
- Python 3.10+
- Ollama installed and running

```bash
ollama pull deepseek-v3.1:671b-cloud


________________________________________________________________
cd aura
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
__________________________________________________________________

```
## ğŸ”‘ TAVILY API KEY 

### set "TAVILY_API_KEY" to access the web search functionality
```bash
$env:TAVILY_API_KEY="tvly-xxxxx
```